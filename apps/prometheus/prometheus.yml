global:
  # every 15s by default
  scrape_interval: 15s

scrape_configs:

  # swarm nodes
  - job_name: docker
    dockerswarm_sd_configs:
      - host: tcp://172.17.0.1:2375
        role: nodes
    relabel_configs:
      # scrape docker metrics on 9323
      - source_labels:
          - __meta_dockerswarm_node_address
        target_label: __address__
        replacement: $1:9323
      # capture the hostname of the running node
      - source_labels:
          - __meta_dockerswarm_node_hostname
        target_label: node
        replacement: $1

  # swarm tasks
  - job_name: swarm-tasks
    dockerswarm_sd_configs:
      - host: tcp://172.17.0.1:2375
        role: tasks
    relabel_configs:
      # only keep containers that should be running
      - source_labels:
          - __meta_dockerswarm_task_desired_state
        regex: running
        action: keep
      # don't scrape the ingress network
      - source_labels:
          - __meta_dockerswarm_network_ingress
        regex: true
        action: drop
      # only scrape enabled services (opt-in)
      - source_labels:
          - __meta_dockerswarm_service_label_prometheus_swarm_enable
        regex: true
        action: keep
      # capture ip of container on swarm network; use ip rather than dns for replicated tasks
      - source_labels:
          - __address__
        target_label: __tmp_container_ip
        regex: (.+):.+
        replacement: $1
      # update address to account for port differences
      - source_labels:
          - __tmp_container_ip
          - __meta_dockerswarm_service_label_prometheus_swarm_port
        target_label: __address__
        regex: (.+);(.+)
        replacement: $1:$2
      # capture the service itself as the "job" (override this single 'tasks' job)
      - source_labels:
          - __meta_dockerswarm_service_name
        target_label: job
        regex: .+_(.+)
        replacement: $1
      # capture the hostname of the running node
      - source_labels:
          - __meta_dockerswarm_node_hostname
        target_label: node
        replacement: $1

  # monitor cable modem
  # configured separately to override interval/timeout
  - job_name: mb8600
    scrape_interval: 1m
    scrape_timeout: 30s
    dockerswarm_sd_configs:
      - host: tcp://172.17.0.1:2375
        role: tasks
    relabel_configs:
      # only keep containers that should be running
      - source_labels:
          - __meta_dockerswarm_task_desired_state
        regex: running
        action: keep
      # only scrape enabled services (opt-in)
      - source_labels:
          - __meta_dockerswarm_service_name
        regex: lab_mb8600-exporter
        action: keep
      # capture ip of container on swarm network; use ip rather than dns for replicated tasks
      - source_labels:
          - __address__
        target_label: __tmp_container_ip
        regex: (.+):.+
        replacement: $1
      # update address to account for port differences
      - source_labels:
          - __tmp_container_ip
          - __meta_dockerswarm_service_label_prometheus_swarm_port
        target_label: __address__
        regex: (.+);(.+)
        replacement: $1:$2
      # capture the service itself as the "job" (so names are controlled by the stack config)
      - source_labels:
          - __meta_dockerswarm_service_name
        target_label: job
        regex: .+_(.+)
        replacement: $1
      # capture the hostname of the running node
      - source_labels:
          - __meta_dockerswarm_node_hostname
        target_label: node
        replacement: $1

  # https://github.com/tg44/OctoPrint-Prometheus-Exporter
  - job_name: octoprint
    scheme: https
    metrics_path: '/plugin/prometheus_exporter/metrics'
    static_configs:
      - targets: ['octoprint.lab.omglolwtfbbq.com']
